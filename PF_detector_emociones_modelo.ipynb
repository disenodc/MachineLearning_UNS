{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAbo/qwTdvle4accruwrgs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/disenodc/MachineLearning_UNS/blob/main/PF_detector_emociones_modelo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo DEtector de emociones - \n",
        "Curso de posgrado: Deteccion de Patrones y Machine Learning\n",
        "\n",
        "* Docente: Claudio Delrieux\n",
        "\n",
        "* Practicos: Valentin Barco\n",
        "\n",
        "* Estudiante: Dario Ceballos\n"
      ],
      "metadata": {
        "id": "3e4EG9PxC7kL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgYiCDXmCv0W"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os,cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 20, 10\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.cross_validation import train_test_split\n",
        "\n",
        "import keras\n",
        "\n",
        "from keras.utils import np_utils\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.metrics import categorical_accuracy\n",
        "from keras.models import model_from_json\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import *\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import os\n",
        "print(os.listdir(\"../input/ck/\"))\n",
        "\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '../input/ck/CK+48'\n",
        "data_dir_list = os.listdir(data_path)\n",
        "\n",
        "img_rows=256\n",
        "img_cols=256\n",
        "num_channel=1\n",
        "\n",
        "num_epoch=10\n",
        "\n",
        "img_data_list=[]\n",
        "\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "    img_list=os.listdir(data_path+'/'+ dataset)\n",
        "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "    for img in img_list:\n",
        "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
        "        #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "        input_img_resize=cv2.resize(input_img,(48,48))\n",
        "        img_data_list.append(input_img_resize)\n",
        "        \n",
        "img_data = np.array(img_data_list)\n",
        "img_data = img_data.astype('float32')\n",
        "img_data = img_data/255\n",
        "img_data.shape"
      ],
      "metadata": {
        "id": "mwgaBLNSEHih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 7\n",
        "\n",
        "num_of_samples = img_data.shape[0]\n",
        "labels = np.ones((num_of_samples,),dtype='int64')\n",
        "\n",
        "labels[0:134]=0 #135\n",
        "labels[135:188]=1 #54\n",
        "labels[189:365]=2 #177\n",
        "labels[366:440]=3 #75\n",
        "labels[441:647]=4 #207\n",
        "labels[648:731]=5 #84\n",
        "labels[732:980]=6 #249\n",
        "\n",
        "names = ['anger','contempt','disgust','fear','happy','sadness','surprise']\n",
        "\n",
        "def getLabel(id):\n",
        "    return ['anger','contempt','disgust','fear','happy','sadness','surprise'][id]"
      ],
      "metadata": {
        "id": "GE1VvJ9zEKOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "\n",
        "#Shuffle the dataset\n",
        "x,y = shuffle(img_data,Y, random_state=2)\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=2)\n",
        "x_test=X_test"
      ],
      "metadata": {
        "id": "dw7Z6oC8EMgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(48,48,3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(7, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')"
      ],
      "metadata": {
        "id": "r1CwtpFCEPbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.get_config()\n",
        "model.layers[0].get_config()\n",
        "model.layers[0].input_shape\n",
        "model.layers[0].output_shape\n",
        "model.layers[0].get_weights()\n",
        "np.shape(model.layers[0].get_weights()[0])\n",
        "model.layers[0].trainable"
      ],
      "metadata": {
        "id": "FDrl_rzMER4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import callbacks\n",
        "filename='model_train_new.csv'\n",
        "filepath=\"Best-weights-my_model-{epoch:03d}-{loss:.4f}-{acc:.4f}.hdf5\"\n",
        "\n",
        "csv_log=callbacks.CSVLogger(filename, separator=',', append=False)\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [csv_log,checkpoint]\n",
        "callbacks_list = [csv_log]"
      ],
      "metadata": {
        "id": "T1KYbW-oERwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(X_train, y_train, batch_size=7, epochs=50, verbose=1, validation_data=(X_test, y_test),callbacks=callbacks_list)"
      ],
      "metadata": {
        "id": "Xl3MFZgzEU3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "test_image = X_test[0:1]\n",
        "print (test_image.shape)\n",
        "\n",
        "print(model.predict(test_image))\n",
        "print(model.predict_classes(test_image))\n",
        "print(y_test[0:1])\n",
        "\n",
        "res = model.predict_classes(X_test[9:18])\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(0, 9):\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    plt.imshow(x_test[i],cmap=plt.get_cmap('gray'))\n",
        "    plt.gca().get_xaxis().set_ticks([])\n",
        "    plt.gca().get_yaxis().set_ticks([])\n",
        "    plt.ylabel('prediction = %s' % getLabel(res[i]), fontsize=14)\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "P7P486JYEUyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizing losses and accuracy\n",
        "%matplotlib inline\n",
        "\n",
        "train_loss=hist.history['loss']\n",
        "val_loss=hist.history['val_loss']\n",
        "train_acc=hist.history['acc']\n",
        "val_acc=hist.history['val_acc']\n",
        "\n",
        "epochs = range(len(train_acc))\n",
        "\n",
        "plt.plot(epochs,train_loss,'r', label='train_loss')\n",
        "plt.plot(epochs,val_loss,'b', label='val_loss')\n",
        "plt.title('train_loss vs val_loss')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs,train_acc,'r', label='train_acc')\n",
        "plt.plot(epochs,val_acc,'b', label='val_acc')\n",
        "plt.title('train_acc vs val_acc')\n",
        "plt.legend()\n",
        "plt.figure()"
      ],
      "metadata": {
        "id": "vMsPVbu5EZOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9POUeLupEZK0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}